{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e023859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, max_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263828be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_id</th>\n",
       "      <th>cpu</th>\n",
       "      <th>mem</th>\n",
       "      <th>mem_gps</th>\n",
       "      <th>mkpi</th>\n",
       "      <th>net_in</th>\n",
       "      <th>net_out</th>\n",
       "      <th>disk_io_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:00:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>17.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.43</td>\n",
       "      <td>29.40</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:05:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.43</td>\n",
       "      <td>29.40</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:10:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>26.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.43</td>\n",
       "      <td>29.40</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:15:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>14.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.44</td>\n",
       "      <td>29.41</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:20:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.44</td>\n",
       "      <td>29.41</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:35:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>14.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.88</td>\n",
       "      <td>32.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:40:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>16.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.88</td>\n",
       "      <td>32.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:45:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.89</td>\n",
       "      <td>32.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:50:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.89</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:55:00</th>\n",
       "      <td>m_103</td>\n",
       "      <td>21.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.89</td>\n",
       "      <td>32.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    machine_id   cpu   mem  mem_gps  mkpi  net_in  net_out  \\\n",
       "time_stamp                                                                   \n",
       "1970-01-06 00:00:00      m_103  17.0  95.0      NaN   NaN   41.43    29.40   \n",
       "1970-01-06 00:05:00      m_103  15.0  95.0      NaN   NaN   41.43    29.40   \n",
       "1970-01-06 00:10:00      m_103  26.0  95.0      NaN   NaN   41.43    29.40   \n",
       "1970-01-06 00:15:00      m_103  14.0  90.0      NaN   NaN   41.44    29.41   \n",
       "1970-01-06 00:20:00      m_103  21.0  93.0      NaN   NaN   41.44    29.41   \n",
       "...                        ...   ...   ...      ...   ...     ...      ...   \n",
       "1970-01-08 23:35:00      m_103  14.0  88.0     2.02   1.0   45.88    32.63   \n",
       "1970-01-08 23:40:00      m_103  16.0  89.0     1.90   0.0   45.88    32.63   \n",
       "1970-01-08 23:45:00      m_103  12.0  88.0     1.28   0.0   45.89    32.63   \n",
       "1970-01-08 23:50:00      m_103  13.0  89.0     2.11   1.0   45.89    32.64   \n",
       "1970-01-08 23:55:00      m_103  21.0  91.0     2.08   0.0   45.89    32.64   \n",
       "\n",
       "                     disk_io_percent  \n",
       "time_stamp                            \n",
       "1970-01-06 00:00:00              2.0  \n",
       "1970-01-06 00:05:00              1.0  \n",
       "1970-01-06 00:10:00              2.0  \n",
       "1970-01-06 00:15:00              4.0  \n",
       "1970-01-06 00:20:00              3.0  \n",
       "...                              ...  \n",
       "1970-01-08 23:35:00              2.0  \n",
       "1970-01-08 23:40:00              2.0  \n",
       "1970-01-08 23:45:00              2.0  \n",
       "1970-01-08 23:50:00              1.0  \n",
       "1970-01-08 23:55:00              1.0  \n",
       "\n",
       "[864 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar dados do CPU\n",
    "machine = 'm_103.csv'\n",
    "workload = pd.read_csv(machine, \n",
    "             names = ['machine_id', 'time_stamp', 'cpu', 'mem', 'mem_gps', \n",
    "                      'mkpi', 'net_in', 'net_out', 'disk_io_percent'])\n",
    "workload.time_stamp = pd.to_datetime(workload.time_stamp, unit='s')\n",
    "workload.set_index('time_stamp', inplace=True)\n",
    "workload = workload.resample('5min').interpolate()\n",
    "workload = workload[-12*24*3:] # 5min * 12 * 24 * 3 = 3 days\n",
    "workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28189179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 54\n",
      "> Model[[30, 5, 10, 11, 0]] 8.932\n",
      "> Model[[30, 5, 10, 21, 0]] 9.307\n",
      "> Model[[30, 5, 10, 30, 0]] 9.163\n",
      "> Model[[30, 5, 20, 11, 0]] 9.185\n",
      "> Model[[30, 5, 20, 21, 0]] 8.937\n",
      "> Model[[30, 5, 20, 30, 0]] 8.852\n",
      "> Model[[30, 5, 30, 11, 0]] 8.668\n",
      "> Model[[30, 5, 30, 21, 0]] 8.727\n",
      "> Model[[30, 5, 30, 30, 0]] 9.288\n",
      "> Model[[30, 11, 10, 11, 0]] 8.403\n",
      "> Model[[30, 11, 10, 21, 0]] 9.087\n",
      "> Model[[30, 11, 10, 30, 0]] 9.308\n",
      "> Model[[30, 11, 20, 11, 0]] 8.402\n",
      "> Model[[30, 11, 20, 21, 0]] 8.384\n",
      "> Model[[30, 11, 20, 30, 0]] 8.433\n",
      "> Model[[30, 11, 30, 11, 0]] 8.416\n",
      "> Model[[30, 11, 30, 21, 0]] 8.313\n",
      "> Model[[30, 11, 30, 30, 0]] 8.316\n",
      "> Model[[30, 15, 10, 11, 0]] 8.318\n",
      "> Model[[30, 15, 10, 21, 0]] 8.442\n",
      "> Model[[30, 15, 10, 30, 0]] 8.383\n",
      "> Model[[30, 15, 20, 11, 0]] 8.717\n",
      "> Model[[30, 15, 20, 21, 0]] 8.370\n",
      "> Model[[30, 15, 20, 30, 0]] 8.395\n",
      "> Model[[30, 15, 30, 11, 0]] 8.195\n",
      "> Model[[30, 15, 30, 21, 0]] 8.182\n",
      "> Model[[30, 15, 30, 30, 0]] 8.232\n",
      "> Model[[12, 5, 10, 11, 0]] 8.757\n",
      "> Model[[12, 5, 10, 21, 0]] 9.334\n",
      "> Model[[12, 5, 10, 30, 0]] 9.755\n",
      "> Model[[12, 5, 20, 11, 0]] 8.791\n",
      "> Model[[12, 5, 20, 21, 0]] 8.499\n",
      "> Model[[12, 5, 20, 30, 0]] 9.593\n",
      "> Model[[12, 5, 30, 11, 0]] 8.915\n",
      "> Model[[12, 5, 30, 21, 0]] 9.019\n",
      "> Model[[12, 5, 30, 30, 0]] 8.902\n",
      "> Model[[12, 11, 10, 11, 0]] 8.322\n",
      "> Model[[12, 11, 10, 21, 0]] 8.349\n",
      "> Model[[12, 11, 10, 30, 0]] 9.200\n",
      "> Model[[12, 11, 20, 11, 0]] 8.301\n",
      "> Model[[12, 11, 20, 21, 0]] 8.281\n",
      "> Model[[12, 11, 20, 30, 0]] 8.523\n",
      "> Model[[12, 11, 30, 11, 0]] 8.175\n",
      "> Model[[12, 11, 30, 21, 0]] 8.217\n",
      "> Model[[12, 11, 30, 30, 0]] 8.505\n",
      "> Model[[12, 15, 10, 11, 0]] 8.312\n",
      "> Model[[12, 15, 10, 21, 0]] 8.407\n",
      "> Model[[12, 15, 10, 30, 0]] 8.438\n",
      "> Model[[12, 15, 20, 11, 0]] 8.343\n",
      "> Model[[12, 15, 20, 21, 0]] 8.269\n",
      "> Model[[12, 15, 20, 30, 0]] 8.345\n",
      "> Model[[12, 15, 30, 11, 0]] 8.199\n",
      "> Model[[12, 15, 30, 21, 0]] 8.182\n",
      "> Model[[12, 15, 30, 30, 0]] 8.261\n",
      "done\n",
      "Tempo: 4:52:43\n",
      "[12, 11, 30, 11, 0] 8.174929190239025\n",
      "[12, 15, 30, 21, 0] 8.181520873050005\n",
      "[30, 15, 30, 21, 0] 8.181990806164853\n"
     ]
    }
   ],
   "source": [
    "# grid search lstm for monthly airline passengers dataset\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data_arr, look_back):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data_arr)-look_back):\n",
    "        d=i+look_back\n",
    "        X.append(data_arr[i:d,])\n",
    "        Y.append(data_arr[d,])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    #data = series_to_supervised(train, n_in=n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = series_to_supervised(train, n_input)#data[:, :-1], data[:, -1]\n",
    "    # reshape input data into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "        history = difference(history, n_diff)\n",
    "    # reshape sample into [samples, timesteps, features]\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    \n",
    "    # reverse scale\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    test = scaler.inverse_transform(test)\n",
    "    \n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    #print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(config[2])]\n",
    "    # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores = scores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [30,12]\n",
    "    n_nodes = [5,11,15]\n",
    "    n_epochs = [10,20,30]\n",
    "    n_batch = [11,21,30]\n",
    "    n_diff = [0]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "        for j in n_nodes:\n",
    "            for k in n_epochs:\n",
    "                for l in n_batch:\n",
    "                    for m in n_diff:\n",
    "                        cfg = [i, j, k, l, m]\n",
    "                        configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "# define dataset\n",
    "data = workload[['cpu']].values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))#LTSM is senstive to the scale of features\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# disable random weigths\n",
    "np.random.seed(1234)\n",
    "set_seed(1234)\n",
    "\n",
    "# data split\n",
    "n_test = int(len(workload)*1/3)\n",
    "# model configs\n",
    "cfg_list = model_configs()\n",
    "# grid search\n",
    "start = datetime.datetime.now()\n",
    "scores = grid_search(data, cfg_list, n_test)\n",
    "print('done')\n",
    "lapsed = datetime.datetime.now() - start\n",
    "print('Tempo: '+str(lapsed).split('.')[0])\n",
    "# list top 10 configs\n",
    "for cfg, error in scores[:3]:\n",
    "    print(cfg, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
