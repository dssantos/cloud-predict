{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7572763d",
   "metadata": {},
   "source": [
    "### Predição do conjunto de dados m_694.csv com o modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e023859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, max_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263828be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_id</th>\n",
       "      <th>cpu</th>\n",
       "      <th>mem</th>\n",
       "      <th>mem_gps</th>\n",
       "      <th>mkpi</th>\n",
       "      <th>net_in</th>\n",
       "      <th>net_out</th>\n",
       "      <th>disk_io_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:00:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.14</td>\n",
       "      <td>39.77</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:05:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>31.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.15</td>\n",
       "      <td>39.78</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:10:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>34.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.15</td>\n",
       "      <td>39.78</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:15:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>31.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.16</td>\n",
       "      <td>39.79</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-06 00:20:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>32.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.16</td>\n",
       "      <td>39.79</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:35:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>86.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.46</td>\n",
       "      <td>44.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:40:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.46</td>\n",
       "      <td>44.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:45:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>85.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.46</td>\n",
       "      <td>44.75</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:50:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.47</td>\n",
       "      <td>44.76</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-08 23:55:00</th>\n",
       "      <td>m_694</td>\n",
       "      <td>87.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.47</td>\n",
       "      <td>44.76</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    machine_id   cpu   mem  mem_gps  mkpi  net_in  net_out  \\\n",
       "time_stamp                                                                   \n",
       "1970-01-06 00:00:00      m_694  25.0  96.0      NaN   NaN   46.14    39.77   \n",
       "1970-01-06 00:05:00      m_694  31.0  97.0      NaN   NaN   46.15    39.78   \n",
       "1970-01-06 00:10:00      m_694  34.0  94.0      NaN   NaN   46.15    39.78   \n",
       "1970-01-06 00:15:00      m_694  31.0  92.0      NaN   NaN   46.16    39.79   \n",
       "1970-01-06 00:20:00      m_694  32.0  94.0      NaN   NaN   46.16    39.79   \n",
       "...                        ...   ...   ...      ...   ...     ...      ...   \n",
       "1970-01-08 23:35:00      m_694  86.0  91.0     0.35   0.0   51.46    44.74   \n",
       "1970-01-08 23:40:00      m_694  86.0  92.0     0.27   0.0   51.46    44.75   \n",
       "1970-01-08 23:45:00      m_694  85.0  92.0     0.45   0.0   51.46    44.75   \n",
       "1970-01-08 23:50:00      m_694  86.0  92.0     0.48   0.0   51.47    44.76   \n",
       "1970-01-08 23:55:00      m_694  87.0  94.0     0.29   0.0   51.47    44.76   \n",
       "\n",
       "                     disk_io_percent  \n",
       "time_stamp                            \n",
       "1970-01-06 00:00:00              5.0  \n",
       "1970-01-06 00:05:00              5.0  \n",
       "1970-01-06 00:10:00              8.0  \n",
       "1970-01-06 00:15:00              4.0  \n",
       "1970-01-06 00:20:00              4.0  \n",
       "...                              ...  \n",
       "1970-01-08 23:35:00              4.0  \n",
       "1970-01-08 23:40:00              6.0  \n",
       "1970-01-08 23:45:00              6.0  \n",
       "1970-01-08 23:50:00              5.0  \n",
       "1970-01-08 23:55:00              5.0  \n",
       "\n",
       "[864 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar dados do CPU\n",
    "machine = 'm_694.csv'\n",
    "workload = pd.read_csv(machine, \n",
    "             names = ['machine_id', 'time_stamp', 'cpu', 'mem', 'mem_gps', \n",
    "                      'mkpi', 'net_in', 'net_out', 'disk_io_percent'])\n",
    "workload.time_stamp = pd.to_datetime(workload.time_stamp, unit='s')\n",
    "workload.set_index('time_stamp', inplace=True)\n",
    "workload = workload.resample('5min').interpolate()\n",
    "workload = workload[-12*24*3:] # 5min * 12 * 24 * 3 = 3 days\n",
    "workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28189179",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 36\n",
      "> Model[[12, 14, 150, 20, 0]] 7.375\n",
      "> Model[[12, 14, 150, 25, 0]] 7.324\n",
      "> Model[[12, 14, 150, 30, 0]] 7.203\n",
      "> Model[[12, 14, 150, 40, 0]] 7.257\n",
      "> Model[[12, 14, 200, 20, 0]] 7.676\n",
      "> Model[[12, 14, 200, 25, 0]] 7.790\n",
      "> Model[[12, 14, 200, 30, 0]] 7.643\n",
      "> Model[[12, 14, 200, 40, 0]] 7.466\n",
      "> Model[[12, 14, 300, 20, 0]] 8.039\n",
      "> Model[[12, 14, 300, 25, 0]] 7.859\n",
      "> Model[[12, 14, 300, 30, 0]] 7.871\n",
      "> Model[[12, 14, 300, 40, 0]] 7.638\n",
      "> Model[[12, 15, 150, 20, 0]] 7.398\n",
      "> Model[[12, 15, 150, 25, 0]] 7.369\n",
      "> Model[[12, 15, 150, 30, 0]] 7.275\n",
      "> Model[[12, 15, 150, 40, 0]] 7.295\n",
      "> Model[[12, 15, 200, 20, 0]] 7.754\n",
      "> Model[[12, 15, 200, 25, 0]] 7.705\n",
      "> Model[[12, 15, 200, 30, 0]] 7.635\n",
      "> Model[[12, 15, 200, 40, 0]] 7.428\n",
      "> Model[[12, 15, 300, 20, 0]] 7.896\n",
      "> Model[[12, 15, 300, 25, 0]] 7.921\n",
      "> Model[[12, 15, 300, 30, 0]] 7.835\n",
      "> Model[[12, 15, 300, 40, 0]] 7.585\n",
      "> Model[[12, 16, 150, 20, 0]] 7.486\n",
      "> Model[[12, 16, 150, 25, 0]] 7.281\n",
      "> Model[[12, 16, 150, 30, 0]] 7.173\n",
      "> Model[[12, 16, 150, 40, 0]] 7.196\n",
      "> Model[[12, 16, 200, 20, 0]] 7.863\n",
      "> Model[[12, 16, 200, 25, 0]] 7.791\n",
      "> Model[[12, 16, 200, 30, 0]] 7.614\n",
      "> Model[[12, 16, 200, 40, 0]] 7.455\n",
      "> Model[[12, 16, 300, 20, 0]] 7.804\n",
      "> Model[[12, 16, 300, 25, 0]] 7.863\n",
      "> Model[[12, 16, 300, 30, 0]] 7.895\n",
      "> Model[[12, 16, 300, 40, 0]] 7.543\n",
      "done\n",
      "Tempo: 1 day, 21:18:28\n",
      "[12, 16, 150, 30, 0] 7.173257003753196\n",
      "[12, 16, 150, 40, 0] 7.1963742806242745\n",
      "[12, 14, 150, 30, 0] 7.203417942610668\n",
      "[12, 14, 150, 40, 0] 7.25745684003683\n",
      "[12, 15, 150, 30, 0] 7.274731327314056\n",
      "[12, 16, 150, 25, 0] 7.280888170103943\n",
      "[12, 15, 150, 40, 0] 7.29453609376497\n",
      "[12, 14, 150, 25, 0] 7.324263178818252\n",
      "[12, 15, 150, 25, 0] 7.369139926473448\n",
      "[12, 14, 150, 20, 0] 7.374554877490175\n"
     ]
    }
   ],
   "source": [
    "# Grid search LSTM\n",
    "# Source: https://machinelearningmastery.com/how-to-grid-search-deep-learning-models-for-time-series-forecasting/\n",
    "\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data_arr, look_back):\n",
    "    X, Y =[], []\n",
    "    for i in range(len(data_arr)-look_back):\n",
    "        d=i+look_back\n",
    "        X.append(data_arr[i:d,])\n",
    "        Y.append(data_arr[d,])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    return sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, order):\n",
    "    return [data[i] - data[i - order] for i in range(order, len(data))]\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    # prepare data\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    # transform series into supervised format\n",
    "    #data = series_to_supervised(train, n_in=n_input)\n",
    "    # separate inputs and outputs\n",
    "    train_x, train_y = series_to_supervised(train, n_input)#data[:, :-1], data[:, -1]\n",
    "    # reshape input data into [samples, timesteps, features]\n",
    "    n_features = 1\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    # fit model\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    return model\n",
    "\n",
    "# forecast with the fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "        history = difference(history, n_diff)\n",
    "    # reshape sample into [samples, timesteps, features]\n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    return correction + yhat[0]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    # seed history with training dataset\n",
    "    history = [x for x in train]\n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    \n",
    "    # reverse scale\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    test = scaler.inverse_transform(test)\n",
    "    \n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    #print(' > %.3f' % error)\n",
    "    return error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def repeat_evaluate(data, config, n_test):\n",
    "    # convert config to a key\n",
    "    key = str(config)\n",
    "    # fit and evaluate the model n times\n",
    "    scores = [walk_forward_validation(data, n_test, config) for _ in range(config[2])]\n",
    "    # summarize score\n",
    "    result = mean(scores)\n",
    "    print('> Model[%s] %.3f' % (key, result))\n",
    "    return (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test):\n",
    "    # evaluate configs\n",
    "    scores = scores = [repeat_evaluate(data, cfg, n_test) for cfg in cfg_list]\n",
    "    # sort configs by error, asc\n",
    "    scores.sort(key=lambda tup: tup[1])\n",
    "    return scores\n",
    "\n",
    "# create a list of configs to try\n",
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_input = [12]\n",
    "    n_nodes = [14,15,16]\n",
    "    n_epochs = [150,200,300]\n",
    "    n_batch = [20,25,30,40]\n",
    "    n_diff = [0]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_input:\n",
    "        for j in n_nodes:\n",
    "            for k in n_epochs:\n",
    "                for l in n_batch:\n",
    "                    for m in n_diff:\n",
    "                        cfg = [i, j, k, l, m]\n",
    "                        configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "# define dataset\n",
    "data = workload[['cpu']].values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))#LTSM is senstive to the scale of features\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# disable random weigths\n",
    "np.random.seed(1234)\n",
    "set_seed(1234)\n",
    "\n",
    "# data split\n",
    "n_test = int(len(workload)*1/3)\n",
    "# model configs\n",
    "cfg_list = model_configs()\n",
    "# grid search\n",
    "start = datetime.datetime.now()\n",
    "scores = grid_search(data, cfg_list, n_test)\n",
    "print('done')\n",
    "lapsed = datetime.datetime.now() - start\n",
    "print('Tempo: '+str(lapsed).split('.')[0])\n",
    "# list top 10 configs\n",
    "for cfg, error in scores[:10]:\n",
    "    print(cfg, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
